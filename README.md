Math Agentic-RAG System
Overview

This project implements an Agentic-RAG (Retrieval-Augmented Generation) system tailored for mathematical queries. It combines PDF-based retrieval with web search fallback to provide accurate, context-aware answers.

The system uses:

LangGraph for building the agent flow.

FastAPI for backend endpoints.

Streamlit as the frontend interface.

FAISS for vector storage of embeddings.

Gemini embeddings and LLMs for understanding queries and generating answers.

Features

Ingests and processes PDF documents from predefined URLs.

Stores embeddings in a FAISS vector database.

Uses similarity search to retrieve the most relevant content.

Falls back to web search if knowledge base does not contain relevant context.

Provides endpoints for interacting with the system.

User-friendly Streamlit interface.

Architecture

The system is structured into three layers:

Frontend (Streamlit)

User enters queries.

Sends query requests to FastAPI backend.

Displays answers retrieved/generated by the agent.

Backend (FastAPI + LangGraph)

Manages query processing flow.

Uses LangGraph agent to decide between knowledge base retrieval or web search.

Retrieves top chunks from FAISS database using Gemini embeddings.

Calls LLM to generate final response.

Knowledge Base

PDF documents ingested from predefined URLs.

Processed into text chunks using RecursiveCharacterTextSplitter.

Embedded using Gemini embeddings.

Stored and indexed in FAISS for fast similarity search.

System Flow
         ┌───────────────┐
         │   User Query   │
         └───────┬───────┘
                 │
                 ▼
        ┌──────────────────┐
        │   Streamlit UI    │
        └───────┬──────────┘
                 │
                 ▼
        ┌──────────────────┐
        │  FastAPI Backend  │
        └───────┬──────────┘
                 │
        ┌────────┴──────────┐
        ▼                   ▼
 ┌──────────────┐     ┌─────────────┐
 │  FAISS DB     │     │  Web Search │
 │ (PDF chunks)  │     │   Fallback  │
 └───────┬───────┘     └──────┬──────┘
         │                    │
         └────────────┬───────┘
                      ▼
            ┌──────────────────┐
            │   Gemini LLM      │
            └─────────┬────────┘
                      │
                      ▼
            ┌──────────────────┐
            │  Final Response   │
            └──────────────────┘

Setup
1. Clone the Repository
git clone https://github.com/your-repo/math-agentic-rag.git
cd math-agentic-rag

2. Install Dependencies
pip install -r requirements.txt

3. Set Environment Variables

Create a .env file:

GEMINI_API_KEY=your_api_key_here

4. Run PDF Processing
python processing.py

5. Start FastAPI Backend
uvicorn app:app --reload

6. Run Streamlit Frontend
streamlit run main.py

API Endpoints
Root

GET /
Returns a simple health check response.

Ask Query

POST /ask
Request body:

{
  "query": "Explain Taylor series expansion"
}


Response:

{
  "answer": "The Taylor series expansion of a function f(x) around a point a is..."
}

Future Improvements

Support for multi-file PDF ingestion.

Integration with more vector databases (Pinecone, Weaviate).

Advanced agent workflows (tool selection, multi-step reasoning).
